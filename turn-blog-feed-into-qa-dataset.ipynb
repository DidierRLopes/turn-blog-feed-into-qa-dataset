{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn blog feed into QA dataset\n",
    "\n",
    "We will use Llama 3.2 (through Ollama) to do the text -> QA.\n",
    "\n",
    "This allows users to run the model locally without sharing potential confidential information with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install all libraries\n",
    "\n",
    "Run:\n",
    "- poetry install\n",
    "- poetry run python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import html2text\n",
    "import requests\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datasets import Dataset\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get started with Ollama\n",
    "\n",
    "Follow instructions here: https://ollama.com/\n",
    "\n",
    "Select a model to run locally using https://ollama.com/search.\n",
    "\n",
    "In this case, I want to run `llama3.2:latest` (https://ollama.com/library/llama3.2).\n",
    "\n",
    "So I run: `ollama pull llama3.2:latest`.\n",
    "\n",
    "<img src=\"./assets/ollama_pull.png\" width=\"600px\" alt=\"ollama pull\">\n",
    "\n",
    "Then, I check that the model has been downloaded with: `ollama list`\n",
    "\n",
    "<img src=\"./assets/ollama_list.png\" width=\"600px\" alt=\"ollama list\">\n",
    "\n",
    "Finally, I test that it works with `ollama run llama3.2:latest`\n",
    "\n",
    "<img src=\"./assets/ollama_run.png\" width=\"600px\" alt=\"ollama run\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test whether we can reach Llama 3.2:latest with Ollama API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_ollama_response(prompt, model=\"llama3.2:latest\", temperature=0.7):\n",
    "    \"\"\"Generate response using Ollama API\"\"\"\n",
    "    response = requests.post('http://localhost:11434/api/generate',\n",
    "                           json={\n",
    "                               \"model\": model,\n",
    "                               \"prompt\": prompt,\n",
    "                               \"temperature\": temperature,\n",
    "                               \"stream\": False\n",
    "                           })\n",
    "    return response.json()['response']\n",
    "\n",
    "output = generate_ollama_response(prompt=\"What is the capital of France?\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that we can retrieve data from the blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'https://didierlopes.com/blog/ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will',\n",
       " 'content_html': '<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png\"></p>\\n<p>Why the future of financial analysis isn\\'t about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.</p>\\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\\n<p>When ChatGPT launched, everyone rushed to build financial chatbots. But they missed two fundamental truths:</p>\\n<ul>\\n<li>The best AI model is useless without access to your data.</li>\\n<li>Access to data isn\\'t enough - AI needs to handle complete workflows, not just conversations.</li>\\n</ul>\\n<p>The problem with financial chatbots:</p>\\n<ol>\\n<li>They can\\'t access your proprietary data</li>\\n<li>They can\\'t handle complex financial workflows</li>\\n<li>They force analysts to work in an unnatural chat interface</li>\\n</ol>\\n<br>\\n<p>Here\\'s how OpenBB solves this:</p>\\n<p>First, we ensure complete data access:</p>\\n<ul>\\n<li>Run everything on-premise or in your VPC</li>\\n<li>Connect any data source: files, APIs, third-party feeds, anything</li>\\n<li>Use a universal data layer that standardizes everything (whether it\\'s CSV, Excel, Snowflake, or APIs)</li>\\n</ul>\\n<p>But the real innovation?</p>\\n<p>We\\'re building AI differently.</p>\\n<p>Instead of forcing analysts to chat with a bot, we\\'re embedding intelligence directly into their workspace.</p>\\n<p>Think dashboards with widgets, not chat windows. Data visualization, not text conversations.</p>\\n<p>This is exactly what Kimberly Tan (partner @ a16z) predicted in <a href=\"https://a16z.com/big-ideas-in-tech-2025/\">her analysis</a>:</p>\\n<blockquote>\\n<p><em>\"Chat was the first experimental interface — now I expect there will be new, novel interaction mechanisms. In this phase, AI agents will be able to take direct action in the workflow, and the UI will be reimagined for humans to review work or do QA.\"</em></p>\\n</blockquote>\\n<br>\\n<p>The result?</p>\\n<p align=\"center\"><img width=\"1200\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png\"></p>\\n<p>A workspace where:</p>\\n<ul>\\n<li>AI appears only when needed (for insights, summaries, or generating visualizations)</li>\\n<li>Firms can adopt AI at their own pace</li>\\n<li>Analysts keep their familiar workflows while gaining AI superpowers</li>\\n</ul>\\n<p>Let me show you this in action.</p>\\n<p>Last week, I shared how <a href=\"https://x.com/mattmaximo1/status/1869413550210625818\">Matt from VanEck</a> built a powerful dashboard integrating multiple distinct data sources on OpenBB. Post with comments can be found <a href=\"https://www.linkedin.com/posts/didier-lopes_today-i-saw-a-glimpse-of-the-future-matt-activity-7275174801860636672-qoy4?utm_source=share&amp;utm_medium=member_desktop\">here</a>.</p>\\n<p>I only showed a screenshot of this dashboard with data.</p>\\n<p>There was no sign of AI in it.</p>\\n<p>However, if I had simply pressed shortcut \"Ctrl+L\", the copilot window would have opened and I would have been able to natively interact with the data - and generate new data from it.</p>\\n<p align=\"center\"><img width=\"1200\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will_1.png\"></p>\\n<p>This demonstrates that the future of financial AI isn\\'t about chatbots - it\\'s about intelligent workspaces.</p>\\n<p>As <a href=\"https://x.com/pyquantnews\">Jason from PyQuantNews</a> astutely observes: <em>\"OpenBB solves the data aggregation and centralization challenge without relying on AI, creating a ton of value from it. And then, you allow users to utilize AI in their workflows as they see fit.\"</em></p>\\n<p>This isn\\'t just another AI product.</p>\\n<p>It\\'s the future of financial analysis - where AI enhances your workspace instead of replacing it.</p>',\n",
       " 'url': 'https://didierlopes.com/blog/ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will',\n",
       " 'title': \"AI Chatbots Won't Revolutionize Finance, But Intelligent Workspaces Will\",\n",
       " 'summary': \"Beyond the AI hype - why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.\",\n",
       " 'date_modified': '2024-12-27T00:00:00.000Z',\n",
       " 'tags': ['openbb',\n",
       "  'artificial intelligence',\n",
       "  'chatgpt',\n",
       "  'financial analytics',\n",
       "  'future of finance']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://didierlopes.com/blog/feed.json\"\n",
    "\n",
    "response = requests.get(url)\n",
    "blog_data = response.json()\n",
    "blog_data[\"items\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean html data to markdown format for AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\n",
      "\n",
      "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png\"></p>\n",
      "<p>Why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactl\n",
      "\n",
      "AFTER\n",
      "\n",
      "Why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.\n",
      "\n",
      "When ChatGPT launched, everyone rushed to build financial chatbots. But they missed two fundamental truths:\n",
      "\n",
      "  * The best AI model is useless\n"
     ]
    }
   ],
   "source": [
    "# Initialize HTML to text converter with stricter settings\n",
    "h = html2text.HTML2Text()\n",
    "h.ignore_links = True  # Now ignore links\n",
    "h.ignore_images = True  # Now ignore images\n",
    "h.ignore_emphasis = True  # Now ignore emphasis\n",
    "h.body_width = 0  # Don't wrap text\n",
    "h.skip_internal_links = True\n",
    "h.inline_links = False\n",
    "h.protect_links = False\n",
    "h.images_to_alt = False  # Don't convert images to alt text\n",
    "h.unicode_snob = True  # Use Unicode instead of ASCII\n",
    "h.wrap_links = False\n",
    "\n",
    "def cleanup_markdown(text):\n",
    "    # Remove any remaining image markdown\n",
    "    text = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove empty lines\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    # Remove any remaining URLs\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    # Remove any remaining markdown links\n",
    "    text = re.sub(r'\\[(.*?)\\]\\(.*?\\)', r'\\1', text)\n",
    "    return text.strip()\n",
    "\n",
    "html_content = blog_data[\"items\"][0][\"content_html\"]\n",
    "\n",
    "content_markdown = h.handle(html_content)\n",
    "content_markdown_further_cleaned = cleanup_markdown(content_markdown)\n",
    "\n",
    "print(\"BEFORE\\n\")\n",
    "print(html_content[:300])\n",
    "print(\"\\nAFTER\\n\")\n",
    "print(content_markdown_further_cleaned[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count sentences in blog\n",
    "\n",
    "This is important as it will allow users to select a number of QA pairs to be extracted based on the number of sentences in each blogpost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 3\n",
      "\n",
      "Sentences:\n",
      "1. The Great Wall of China was built over many centuries by different dynasties.\n",
      "2. Construction began more than 2,300 years ago and continued through the Ming Dynasty in the 1600s.\n",
      "3. The wall was primarily built for defense purposes and spans approximately 13,171 miles.\n"
     ]
    }
   ],
   "source": [
    "def count_sentences_spacy(text):\n",
    "    # Load the English language model\n",
    "    # Use 'python -m spacy download en_core_web_sm' if not already downloaded\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Get sentences\n",
    "    sentences = list(doc.sents)\n",
    "    \n",
    "    return len(sentences), sentences\n",
    "\n",
    "# Example usage\n",
    "text = \"\"\"The Great Wall of China was built over many centuries by different dynasties. \n",
    "Construction began more than 2,300 years ago and continued through the Ming Dynasty in the 1600s. \n",
    "The wall was primarily built for defense purposes and spans approximately 13,171 miles.\"\"\"\n",
    "\n",
    "count, sentences = count_sentences_spacy(text)\n",
    "print(f\"Number of sentences: {count}\")\n",
    "print(\"\\nSentences:\")\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {sent.text.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate QA pairs from text\n",
    "\n",
    "We are going to utilize Conversational Question Answering Dataset (CoQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Q&A Pairs:\n",
      "\n",
      "Q: Didier, you mentioned that when ChatGPT launched, everyone rushed to build financial chatbots  What do you think was the initial excitement about building these chatbots, and what did they miss in their approach?\n",
      "A: The initial excitement around building financial chatbots was likely driven by the promise of automation and efficiency gains. However, they missed that the best AI model is only as good as the data it has access to, and that true value comes from integrating AI into a complete workflow, not just a conversational interface.\n",
      "\n",
      "Q: You stated that the best AI model is useless without access to your data  Can you elaborate on why having access to data is crucial for effective AI implementation in financial analysis? What types of data do you think are most important to have?\n",
      "A: Access to high-quality, relevant data is critical for training and fine-tuning AI models in finance. Proprietary company data, such as financial statements, transactions, and market data, is essential for building accurate predictive models. Having access to this data enables AI to learn patterns, identify trends, and make informed decisions, making it a crucial component of effective AI implementation.\n",
      "\n",
      "Q: You mentioned that chatbots can't handle complex financial workflows  What kind of complexities are we talking about here? Are there specific areas of finance where AI is more effective than humans, or vice versa?\n",
      "A: Complex financial workflows involve intricate data relationships, nuanced regulatory requirements, and high-stakes decision-making. In areas like investment analysis, portfolio management, and risk assessment, AI excels at processing vast amounts of data, identifying patterns, and providing predictive insights that humans might miss. However, in tasks requiring human judgment, creativity, and emotional intelligence, such as financial planning, tax consulting, or business strategy development, human expertise remains invaluable.\n",
      "\n",
      "Q: OpenBB's approach seems to focus on creating intelligent workspaces rather than relying on chatbots  Can you walk us through how your platform ensures complete data access for users? How do you connect different data sources?\n",
      "A: At OpenBB, we ensure complete data access by allowing users to run everything on-premise or in their VPC, connecting any data source via files, APIs, third-party feeds, or a universal data layer that standardizes all formats. This universal data layer enables seamless integration of disparate data sources, such as CSV, Excel, Snowflake, or APIs, into a single workspace.\n",
      "\n",
      "Q: You mentioned embedding intelligence directly into users' workspaces, rather than forcing them to chat with a bot  What does this mean in practice? How do you envision these intelligent workspaces evolving over time?\n",
      "A: In practice, our intelligent workspaces embed AI capabilities within the user interface, allowing analysts to access data-driven insights and visualizations seamlessly. Over time, we envision these workspaces evolving to incorporate more advanced features such as real-time predictive analytics, automated report generation, and collaborative tools that empower teams to make informed decisions together. By providing a customizable, intuitive environment, OpenBB enables users to harness the power of AI without sacrificing their existing workflows or productivity.\n"
     ]
    }
   ],
   "source": [
    "def generate_qa_pairs(text, min_question_length=20):\n",
    "    # Count sentences to determine the number of QA pairs to generate\n",
    "    num_sentences, _ = count_sentences_spacy(text)  # Unpack the tuple\n",
    "    # Generate 1 QA pair per 5 sentences, minimum 1 pair\n",
    "    num_qa_pairs = max(1, num_sentences // 3) \n",
    "    \n",
    "    # Generate questions\n",
    "    question_prompt = f\"\"\"Generate {num_qa_pairs} specific questions that capture the main points from this post written by Didier Lopes (founder and CEO of OpenBB). \n",
    "    Create a series of questions that follow a conversational flow, as if in a dialogue about the content.\n",
    "    Each question should build upon the previous ones, exploring the topic in more depth.\n",
    "    Focus on what you found most interesting, original, or important.\n",
    "    Ensure questions are diverse, covering different aspects of the content.\n",
    "    Avoid generic questions and those answerable with a simple yes/no.\n",
    "    Questions should encourage detailed responses that reveal key information from the text.\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Questions (in conversational order):\"\"\"\n",
    "\n",
    "    # Higher temperature for more diverse questions\n",
    "    questions_response = generate_ollama_response(\n",
    "        question_prompt,\n",
    "        model=\"llama3.2:latest\",\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    # Parse questions (assuming numbered list format)\n",
    "    questions = [q.strip() for q in questions_response.split('\\n') \n",
    "                if q.strip() and any(c.isdigit() for c in q)]\n",
    "    \n",
    "    qa_pairs = []\n",
    "    for question in questions:\n",
    "        # Remove leading numbers and dots\n",
    "        question = ' '.join(question.split('.')[1:]).strip()\n",
    "        \n",
    "        # Filter out low-quality questions\n",
    "        if (len(question) < min_question_length or \n",
    "            question.lower().startswith(('what is', 'tell me about', 'can you')) or\n",
    "            'text' in question.lower()):\n",
    "            continue\n",
    "        \n",
    "        # Generate answer\n",
    "        answer_prompt = f\"\"\"You are Didier Lopes (founder and CEO of OpenBB).\n",
    "        You wrote the post where this question was taken from.\n",
    "        Provide an extremely concise answer, no longer than 2-3 sentences.\n",
    "        Include key details or numbers if absolutely necessary.\n",
    "        Avoid all unnecessary information.\n",
    "        Be direct and to the point.\n",
    "        \n",
    "        Context: {text}\n",
    "        Question: {question}\n",
    "        Answer (2-3 sentences max): \"\"\"\n",
    "        \n",
    "        # Lower temperature for more concise answers\n",
    "        answer = generate_ollama_response(\n",
    "            answer_prompt,\n",
    "            model=\"llama3.2:latest\",\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # Filter answers that have too little information or model wasn't able to generate a proper answer\n",
    "        if (len(answer) > 40 and\n",
    "            not any(x in answer.lower() for x in ['cannot', 'text does not', 'no information'])):\n",
    "            qa_pairs.append({\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"context\": text\n",
    "            })\n",
    "    \n",
    "    # Remove duplicates\n",
    "    filtered_pairs = []\n",
    "    seen_questions = set()\n",
    "    for pair in qa_pairs:\n",
    "        q_normalized = ' '.join(pair['question'].lower().split())\n",
    "        # Check if question is similar to any previously seen questions\n",
    "        if not any(SequenceMatcher(None, q_normalized, sq).ratio() > 0.8 for sq in seen_questions):\n",
    "            seen_questions.add(q_normalized)\n",
    "            filtered_pairs.append(pair)\n",
    "    \n",
    "    return filtered_pairs\n",
    "\n",
    "qa_pairs = generate_qa_pairs(content_markdown_further_cleaned)\n",
    "\n",
    "print(\"Generated Q&A Pairs:\")\n",
    "for pair in qa_pairs[:5]:\n",
    "    print(f\"\\nQ: {pair['question']}\")\n",
    "    print(f\"A: {pair['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the QA datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'You mentioned that when ChatGPT launched, everyone rushed to build financial chatbots  What were some of the fundamental truths that those who built these chatbots missed?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Those building financial chatbots missed two fundamental truths:\\n\\n1. AI models are useless without access to your data.\\n2. Access to data isn't enough - AI needs to handle complete workflows, not just conversations.\\n\\nThese limitations led to chatbots that can't access proprietary data, can't handle complex workflows and restrict analysts to an unnatural chat interface.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'I noticed that OpenBB emphasizes complete data access as a key component of its platform  Can you tell us more about how this is achieved and what kind of data sources are supported?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'At OpenBB, we ensure complete data access by allowing users to run everything on-premise or in their VPC. We also support a wide range of data sources, including files, APIs, third-party feeds, and even standardizing data from different formats like CSV, Excel, Snowflake, or APIs through our universal data layer.'},\n",
       " {'role': 'user',\n",
       "  'content': \"You mentioned that traditional chatbots can't handle complex financial workflows  How does OpenBB's approach address these complexities, and what kinds of workflows can users expect to be supported?\"}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the format to be saved in the dataset\n",
    "qa_dataset = {\n",
    "    \"title\": [],\n",
    "    \"conversation\": [],\n",
    "    \"context\": [],\n",
    "    \"url\": [],\n",
    "    \"date\": []\n",
    "}\n",
    "# Process each post\n",
    "for post in blog_data['items'][:2]:\n",
    "    # Convert HTML to markdown\n",
    "    content_markdown = h.handle(post['content_html'])\n",
    "    content_markdown_further_cleaned = cleanup_markdown(content_markdown)\n",
    "    \n",
    "    # Parse the date string into a datetime object\n",
    "    try:\n",
    "        date_obj = datetime.fromisoformat( post['date_modified'].replace('Z', '+00:00'))\n",
    "        # Format the date as YYYY-MM-DD\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        # If date parsing fails, use a placeholder\n",
    "        formatted_date = 'Unknown'\n",
    "\n",
    "    # Generate QA pairs\n",
    "    qa_pairs = generate_qa_pairs(content_markdown_further_cleaned)\n",
    "\n",
    "    # Create the conversation structure\n",
    "    conversation = []\n",
    "    for pair in qa_pairs:\n",
    "        conversation.extend([\n",
    "            {\"role\": \"user\", \"content\": pair['question']},\n",
    "            {\"role\": \"assistant\", \"content\": pair['answer']}\n",
    "        ])\n",
    "\n",
    "    # Append to the formatted data structure directly\n",
    "    qa_dataset[\"title\"].append(post['title'])\n",
    "    qa_dataset[\"conversation\"].append(conversation)\n",
    "    qa_dataset[\"context\"].append(content_markdown_further_cleaned)\n",
    "    qa_dataset[\"url\"].append(post['url'])\n",
    "    qa_dataset[\"date\"].append(formatted_date)\n",
    "\n",
    "qa_dataset[\"conversation\"][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the dataset to HuggingFace\n",
    "\n",
    "Set your HF_TOKEN through Hugging Face, following https://huggingface.co/docs/hub/en/security-tokens.\n",
    "\n",
    "Notice that you will need \"write\" permissions to push the dataset into HuggingFace.\n",
    "\n",
    "Copy the HF_TOKEN created and paste it in an .env file as following:\n",
    "\n",
    "```\n",
    "HF_TOKEN=hf_123abc456def\n",
    "```\n",
    "\n",
    "Then set your dataset_repo by setting your HuggingFace username followed by a / with the name that you want this dataset repository to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 203.51ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/didierlopes/test-my-blog-qa-dataset/commit/8918bbeb475e08ed60deb2302055ecb5628f6565', commit_message='Upload dataset', commit_description='', oid='8918bbeb475e08ed60deb2302055ecb5628f6565', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/didierlopes/test-my-blog-qa-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='didierlopes/test-my-blog-qa-dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_repo = \"didierlopes/my-blog-qa-dataset\"\n",
    "\n",
    "# Create the Dataset object\n",
    "dataset = Dataset.from_dict(qa_dataset)\n",
    "\n",
    "# Save the dataset to the HuggingFace Hub\n",
    "dataset.push_to_hub(\n",
    "    dataset_repo,\n",
    "    token=os.getenv('HF_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa-dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
