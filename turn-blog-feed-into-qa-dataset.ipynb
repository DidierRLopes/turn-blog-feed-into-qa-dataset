{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn blog feed into QA dataset\n",
    "\n",
    "We will use Llama 3.2 (through Ollama) to do the text -> QA.\n",
    "\n",
    "This allows users to run the model locally without sharing potential confidential information with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install all libraries\n",
    "\n",
    "Run:\n",
    "- poetry install\n",
    "- poetry run python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import html2text\n",
    "import requests\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datasets import Dataset\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get started with Ollama\n",
    "\n",
    "Follow instructions here: https://ollama.com/\n",
    "\n",
    "Select a model to run locally using https://ollama.com/search.\n",
    "\n",
    "In this case, I want to run `llama3.2:latest` (https://ollama.com/library/llama3.2).\n",
    "\n",
    "So I run: `ollama pull llama3.2:latest`.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DidierRLopes/turn-blog-feed-into-qa-dataset/main/assets/ollama_pull.png\" width=\"600px\" alt=\"ollama pull\">\n",
    "\n",
    "Then, I check that the model has been downloaded with: `ollama list`\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DidierRLopes/turn-blog-feed-into-qa-dataset/main/assets/ollama_list.png\" width=\"600px\" alt=\"ollama list\">\n",
    "\n",
    "Finally, I test that it works with `ollama run llama3.2:latest`\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/DidierRLopes/turn-blog-feed-into-qa-dataset/main/assets/ollama_run.png\" width=\"600px\" alt=\"ollama run\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test whether we can reach Llama 3.2:latest with Ollama API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_ollama_response(prompt, model=\"llama3.2:latest\", temperature=0.7):\n",
    "    \"\"\"Generate response using Ollama API\"\"\"\n",
    "    response = requests.post('http://localhost:11434/api/generate',\n",
    "                           json={\n",
    "                               \"model\": model,\n",
    "                               \"prompt\": prompt,\n",
    "                               \"temperature\": temperature,\n",
    "                               \"stream\": False\n",
    "                           })\n",
    "    return response.json()['response']\n",
    "\n",
    "output = generate_ollama_response(prompt=\"What is the capital of France?\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that we can retrieve data from the blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'https://didierlopes.com/blog/ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will',\n",
       " 'content_html': '<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png\"></p>\\n<p>Why the future of financial analysis isn\\'t about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.</p>\\n<div style=\"border-top:1px solid #0088CC;margin:1.5em 0\"></div>\\n<p>When ChatGPT launched, everyone rushed to build financial chatbots. But they missed two fundamental truths:</p>\\n<ul>\\n<li>The best AI model is useless without access to your data.</li>\\n<li>Access to data isn\\'t enough - AI needs to handle complete workflows, not just conversations.</li>\\n</ul>\\n<p>The limitations of most financial chatbots:</p>\\n<ol>\\n<li>They only work on a specific dataset (e.g 10-K/10-Q)</li>\\n<li>They can\\'t handle complex financial workflows</li>\\n<li>They force analysts to work in an unnatural chat interface</li>\\n</ol>\\n<br>\\n<p>Here\\'s how OpenBB addresses these challenges:</p>\\n<p>First, we ensure comprehensive data access:</p>\\n<ul>\\n<li>Run everything on-premise or in your VPC</li>\\n<li>Connect any data source: internal files, APIs, third-party feeds, market data - anything</li>\\n<li>Use a universal data layer that standardizes everything (whether it\\'s CSV, Excel, Snowflake, or APIs)</li>\\n</ul>\\n<p>But the real innovation?</p>\\n<p>We\\'re building AI differently.</p>\\n<p>Instead of forcing analysts to chat with a bot, we\\'re embedding intelligence directly into their workspace.</p>\\n<p>Think dashboards with widgets, not chat windows. Data visualization, not text conversations.</p>\\n<p>This is exactly what Kimberly Tan (partner @ a16z) predicted in <a href=\"https://a16z.com/big-ideas-in-tech-2025/\">her analysis</a>:</p>\\n<blockquote>\\n<p><em>\"Chat was the first experimental interface â€” now I expect there will be new, novel interaction mechanisms. In this phase, AI agents will be able to take direct action in the workflow, and the UI will be reimagined for humans to review work or do QA.\"</em></p>\\n</blockquote>\\n<br>\\n<p>The result?</p>\\n<p align=\"center\"><img width=\"1200\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png\"></p>\\n<p>A workspace where:</p>\\n<ul>\\n<li>AI appears only when needed (for insights, summaries, or generating visualizations)</li>\\n<li>Firms can adopt AI at their own pace</li>\\n<li>Analysts keep their familiar workflows while gaining AI superpowers</li>\\n</ul>\\n<p>Let me show you this in action.</p>\\n<p>Last week, I shared how <a href=\"https://x.com/mattmaximo1/status/1869413550210625818\">Matt from VanEck</a> built a powerful dashboard integrating multiple distinct data sources on OpenBB. Post with comments can be found <a href=\"https://www.linkedin.com/posts/didier-lopes_today-i-saw-a-glimpse-of-the-future-matt-activity-7275174801860636672-qoy4?utm_source=share&amp;utm_medium=member_desktop\">here</a>.</p>\\n<p>I only showed a screenshot of this dashboard with data.</p>\\n<p>There was no sign of AI in it.</p>\\n<p>However, if I had simply pressed shortcut \"Ctrl+L\", the copilot window would have opened and I would have been able to natively interact with the data - and generate new data from it.</p>\\n<p align=\"center\"><img width=\"1200\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will_1.png\"></p>\\n<p>This demonstrates that the future of financial AI isn\\'t about chatbots - it\\'s about intelligent workspaces.</p>\\n<p>As <a href=\"https://x.com/pyquantnews\">Jason from PyQuantNews</a> astutely observes: <em>\"OpenBB solves the data aggregation and centralization challenge without relying on AI, creating a ton of value from it. And then, you allow users to utilize AI in their workflows as they see fit.\"</em></p>\\n<p>This isn\\'t just another AI product.</p>\\n<p>It\\'s the future of financial analysis - where AI enhances your workspace instead of replacing it.</p>',\n",
       " 'url': 'https://didierlopes.com/blog/ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will',\n",
       " 'title': \"AI chatbots won't revolutionize finance, but intelligent workspaces will\",\n",
       " 'summary': \"Beyond the AI hype - why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.\",\n",
       " 'date_modified': '2024-12-27T00:00:00.000Z',\n",
       " 'tags': ['openbb',\n",
       "  'artificial intelligence',\n",
       "  'chatgpt',\n",
       "  'financial analytics',\n",
       "  'future of finance']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://didierlopes.com/blog/feed.json\"\n",
    "\n",
    "response = requests.get(url)\n",
    "blog_data = response.json()\n",
    "blog_data[\"items\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean html data to markdown format for AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\n",
      "\n",
      "<p align=\"center\"><img width=\"600\" src=\"https://didierlopes.com/blog/2024-12-27-ai-chatbots-wont-revolutionize-finance-but-intelligent-workspaces-will.png\"></p>\n",
      "<p>Why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactl\n",
      "\n",
      "AFTER\n",
      "\n",
      "Why the future of financial analysis isn't about chatbots, but about intelligent workspaces that combine your data, tools, and AI exactly when you need them.\n",
      "\n",
      "When ChatGPT launched, everyone rushed to build financial chatbots. But they missed two fundamental truths:\n",
      "\n",
      "  * The best AI model is useless\n"
     ]
    }
   ],
   "source": [
    "# Initialize HTML to text converter with stricter settings\n",
    "h = html2text.HTML2Text()\n",
    "h.ignore_links = True  # Now ignore links\n",
    "h.ignore_images = True  # Now ignore images\n",
    "h.ignore_emphasis = True  # Now ignore emphasis\n",
    "h.body_width = 0  # Don't wrap text\n",
    "h.skip_internal_links = True\n",
    "h.inline_links = False\n",
    "h.protect_links = False\n",
    "h.images_to_alt = False  # Don't convert images to alt text\n",
    "h.unicode_snob = True  # Use Unicode instead of ASCII\n",
    "h.wrap_links = False\n",
    "\n",
    "def cleanup_markdown(text):\n",
    "    # Remove any remaining image markdown\n",
    "    text = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove empty lines\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text)\n",
    "    # Remove any remaining URLs\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    # Remove any remaining markdown links\n",
    "    text = re.sub(r'\\[(.*?)\\]\\(.*?\\)', r'\\1', text)\n",
    "    return text.strip()\n",
    "\n",
    "html_content = blog_data[\"items\"][0][\"content_html\"]\n",
    "\n",
    "content_markdown = h.handle(html_content)\n",
    "content_markdown_further_cleaned = cleanup_markdown(content_markdown)\n",
    "\n",
    "print(\"BEFORE\\n\")\n",
    "print(html_content[:300])\n",
    "print(\"\\nAFTER\\n\")\n",
    "print(content_markdown_further_cleaned[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count sentences in blog\n",
    "\n",
    "This is important as it will allow users to select a number of QA pairs to be extracted based on the number of sentences in each blogpost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 3\n",
      "\n",
      "Sentences:\n",
      "1. The Great Wall of China was built over many centuries by different dynasties.\n",
      "2. Construction began more than 2,300 years ago and continued through the Ming Dynasty in the 1600s.\n",
      "3. The wall was primarily built for defense purposes and spans approximately 13,171 miles.\n"
     ]
    }
   ],
   "source": [
    "def count_sentences_spacy(text):\n",
    "    # Load the English language model\n",
    "    # Use 'python -m spacy download en_core_web_sm' if not already downloaded\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Get sentences\n",
    "    sentences = list(doc.sents)\n",
    "    \n",
    "    return len(sentences), sentences\n",
    "\n",
    "# Example usage\n",
    "text = \"\"\"The Great Wall of China was built over many centuries by different dynasties. \n",
    "Construction began more than 2,300 years ago and continued through the Ming Dynasty in the 1600s. \n",
    "The wall was primarily built for defense purposes and spans approximately 13,171 miles.\"\"\"\n",
    "\n",
    "count, sentences = count_sentences_spacy(text)\n",
    "print(f\"Number of sentences: {count}\")\n",
    "print(\"\\nSentences:\")\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {sent.text.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate QA pairs from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Q&A Pairs:\n",
      "\n",
      "Q: You wrote about why the future of financial analysis isn't about chatbots, but rather intelligent workspaces  Can you elaborate on what inspired this perspective?\n",
      "A: I was initially excited by ChatGPT's launch and saw an opportunity to build a financial chatbot. However, as I dug deeper, I realized that my initial enthusiasm was misplaced. The limitations of traditional financial chatbots - lack of comprehensive data access and inability to handle complex workflows - became clear, leading me to shift focus towards creating intelligent workspaces that combine data, tools, and AI.\n",
      "\n",
      "Q: How did the launch of ChatGPT impact your thinking on this topic?\n",
      "A: The launch of ChatGPT accelerated my focus on developing intelligent workspaces, as I realized that relying solely on chatbots was not a solution. Instead, I prioritized creating an ecosystem that seamlessly integrates data, tools, and AI to enhance user workflows. This shift in approach is crucial for unlocking the full potential of financial analysis.\n",
      "\n",
      "Q: What do you believe are the main limitations of current financial chatbots?\n",
      "A: Current financial chatbots have fundamental limitations, including inability to handle complex workflows and limited data access. They also force analysts into unnatural chat interfaces, stifling productivity and creativity. By contrast, OpenBB addresses these challenges by providing comprehensive data access and embedding AI directly into a workspace, where it enhances human analysis, not replaces it.\n",
      "\n",
      "Q: How do these limitations affect analysts in their daily work?\n",
      "A: These limitations force analysts to spend more time navigating chat interfaces, manually formatting data, and reworking workflows. This can lead to increased frustration, errors, and decreased productivity. Analysts are instead limited to relying on AI as a separate tool, rather than having it seamlessly integrated into their workflow.\n",
      "\n",
      "Q: You mentioned that OpenBB addresses the challenges faced by traditional financial chatbots  What are some key aspects of your approach?\n",
      "A: Our comprehensive data access allows analysts to connect any data source, including internal files, APIs, and market data. We provide a universal data layer that standardizes everything, enabling seamless integration with various tools and workflows. This foundation empowers AI to appear only when needed, enhancing the workspace without replacing it.\n"
     ]
    }
   ],
   "source": [
    "def generate_qa_pairs(text, min_question_length=20):\n",
    "    # Count sentences to determine the number of QA pairs to generate\n",
    "    num_sentences, _ = count_sentences_spacy(text)  # Unpack the tuple\n",
    "    # Generate 1 QA pair per 1 sentence, minimum 1 pair\n",
    "    num_qa_pairs = max(1, num_sentences) \n",
    "    \n",
    "    # Generate questions\n",
    "    question_prompt = f\"\"\"Generate {num_qa_pairs} specific questions that capture the main points from this post written by Didier Lopes (founder and CEO of OpenBB). \n",
    "    Create a series of questions that follow a conversational flow, as if in a dialogue about the content.\n",
    "    Each question should build upon the previous ones, exploring the topic in more depth.\n",
    "    Focus on what you found most interesting, original, or important.\n",
    "    Ensure questions are diverse, covering different aspects of the content.\n",
    "    Avoid generic questions and those answerable with a simple yes/no.\n",
    "    Questions should encourage detailed responses that reveal key information from the text.\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Questions (in conversational order):\"\"\"\n",
    "\n",
    "    # Higher temperature for more diverse questions\n",
    "    questions_response = generate_ollama_response(\n",
    "        question_prompt,\n",
    "        model=\"llama3.2:latest\",\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    # Parse questions (assuming numbered list format)\n",
    "    questions = [q.strip() for q in questions_response.split('\\n') \n",
    "                if q.strip() and any(c.isdigit() for c in q)]\n",
    "    \n",
    "    qa_pairs = []\n",
    "    for question in questions:\n",
    "        # Remove leading numbers and dots\n",
    "        question = ' '.join(question.split('.')[1:]).strip()\n",
    "        \n",
    "        # Filter out low-quality questions\n",
    "        if (len(question) < min_question_length or \n",
    "            question.lower().startswith(('what is', 'tell me about', 'can you')) or\n",
    "            'text' in question.lower()):\n",
    "            continue\n",
    "        \n",
    "        # Generate answer\n",
    "        answer_prompt = f\"\"\"You are Didier Lopes (founder and CEO of OpenBB).\n",
    "        You wrote the post where this question was taken from.\n",
    "        Provide an extremely concise answer, no longer than 2-3 sentences.\n",
    "        Include key details or numbers if absolutely necessary.\n",
    "        Avoid all unnecessary information.\n",
    "        Be direct and to the point.\n",
    "        \n",
    "        Context: {text}\n",
    "        Question: {question}\n",
    "        Answer (2-3 sentences max): \"\"\"\n",
    "        \n",
    "        # Lower temperature for more concise answers\n",
    "        answer = generate_ollama_response(\n",
    "            answer_prompt,\n",
    "            model=\"llama3.2:latest\",\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # Filter answers that have too little information or model wasn't able to generate a proper answer\n",
    "        if (len(answer) > 40 and\n",
    "            not any(x in answer.lower() for x in ['cannot', 'text does not', 'no information'])):\n",
    "            qa_pairs.append({\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"context\": text\n",
    "            })\n",
    "    \n",
    "    # Remove duplicates\n",
    "    filtered_pairs = []\n",
    "    seen_questions = set()\n",
    "    for pair in qa_pairs:\n",
    "        q_normalized = ' '.join(pair['question'].lower().split())\n",
    "        # Check if question is similar to any previously seen questions\n",
    "        if not any(SequenceMatcher(None, q_normalized, sq).ratio() > 0.8 for sq in seen_questions):\n",
    "            seen_questions.add(q_normalized)\n",
    "            filtered_pairs.append(pair)\n",
    "    \n",
    "    return filtered_pairs\n",
    "\n",
    "qa_pairs = generate_qa_pairs(content_markdown_further_cleaned)\n",
    "\n",
    "print(\"Generated Q&A Pairs:\")\n",
    "for pair in qa_pairs[:5]:\n",
    "    print(f\"\\nQ: {pair['question']}\")\n",
    "    print(f\"A: {pair['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the QA datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"What led you to believe that financial chatbots wouldn't be enough for the future of financial analysis?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"We saw firsthand how limited traditional financial chatbots were, with issues like only working on specific datasets, struggling with complex workflows and unnatural interfaces. We realized that these limitations didn't leverage the true power of AI, which is to enhance human workspaces, not replace them entirely. Our approach focuses on integrating intelligence into the analyst's workspace, rather than forcing a chat interface.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"How do you think the limitations of most financial chatbots (e g , working only on specific datasets, handling complex workflows) impact analysts' productivity and efficiency?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Most financial chatbots significantly limit analysts' productivity due to their narrow dataset focus, inability to handle complex workflows, and unnatural chat interface. This forces analysts to spend more time navigating these limitations, reducing overall efficiency and effectiveness. By contrast, OpenBB's intelligent workspaces empower analysts with AI-driven insights while maintaining control over familiar workflows.\"},\n",
       " {'role': 'user',\n",
       "  'content': 'How do you ensure that OpenBB can connect with various data sources, including internal files, APIs, and third-party feeds?'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the format to be saved in the dataset\n",
    "qa_dataset = {\n",
    "    \"title\": [],\n",
    "    \"conversation\": [],\n",
    "    \"context\": [],\n",
    "    \"url\": [],\n",
    "    \"date\": []\n",
    "}\n",
    "# Process each post\n",
    "for post in blog_data['items']:\n",
    "    # Convert HTML to markdown\n",
    "    content_markdown = h.handle(post['content_html'])\n",
    "    content_markdown_further_cleaned = cleanup_markdown(content_markdown)\n",
    "    \n",
    "    # Parse the date string into a datetime object\n",
    "    try:\n",
    "        date_obj = datetime.fromisoformat( post['date_modified'].replace('Z', '+00:00'))\n",
    "        # Format the date as YYYY-MM-DD\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        # If date parsing fails, use a placeholder\n",
    "        formatted_date = 'Unknown'\n",
    "\n",
    "    # Generate QA pairs\n",
    "    qa_pairs = generate_qa_pairs(content_markdown_further_cleaned)\n",
    "\n",
    "    # Create the conversation structure\n",
    "    conversation = []\n",
    "    for pair in qa_pairs:\n",
    "        conversation.extend([\n",
    "            {\"role\": \"user\", \"content\": pair['question']},\n",
    "            {\"role\": \"assistant\", \"content\": pair['answer']}\n",
    "        ])\n",
    "\n",
    "    # Append to the formatted data structure directly\n",
    "    qa_dataset[\"title\"].append(post['title'])\n",
    "    qa_dataset[\"conversation\"].append(conversation)\n",
    "    qa_dataset[\"context\"].append(content_markdown_further_cleaned)\n",
    "    qa_dataset[\"url\"].append(post['url'])\n",
    "    qa_dataset[\"date\"].append(formatted_date)\n",
    "\n",
    "qa_dataset[\"conversation\"][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the dataset to HuggingFace\n",
    "\n",
    "Set your HF_TOKEN through Hugging Face, following https://huggingface.co/docs/hub/en/security-tokens.\n",
    "\n",
    "Notice that you will need \"write\" permissions to push the dataset into HuggingFace.\n",
    "\n",
    "Copy the HF_TOKEN created and paste it in an .env file as following:\n",
    "\n",
    "```\n",
    "HF_TOKEN=hf_123abc456def\n",
    "```\n",
    "\n",
    "Then set your dataset_repo by setting your HuggingFace username followed by a / with the name that you want this dataset repository to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d18c35abdb483eb8c9098bd3f83d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e8883dee924e8f9aa87c29bd7d3194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/didierlopes/my-blog-qa-dataset/commit/9e003cba64af82f8b95ce4624850dccf6b34c776', commit_message='Upload dataset', commit_description='', oid='9e003cba64af82f8b95ce4624850dccf6b34c776', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/didierlopes/my-blog-qa-dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='didierlopes/my-blog-qa-dataset'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_repo = \"didierlopes/my-blog-qa-dataset\"\n",
    "\n",
    "# Create the Dataset object\n",
    "dataset = Dataset.from_dict(qa_dataset)\n",
    "\n",
    "# Save the dataset to the HuggingFace Hub\n",
    "dataset.push_to_hub(\n",
    "    dataset_repo,\n",
    "    token=os.getenv('HF_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa-dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
